### 👤 个人信息  
- **姓名:** 刘旭昊  
- 📞 **联系方式:** 13265143387 | 📧 [liuxh256@mail2.sysu.edu.cn](mailto:liuxh256@mail2.sysu.edu.cn)  
- 📍 **地址:** 广东 珠海  
- 💻 **GitHub:** [GitHub](https://github.com/monetly)
---
### 🎓 教育背景  
##### 中山大学 - 2022 ~ 2026（预计）  
**专业:** 数学与应用数学 | **学位:** 学士（在读）  
- 📚 **主修课程:**  
  - 数学分析、数据结构与算法、高等代数、信息论、初等数论、离散数学、机器学习与深度学习
---
### 💼 工作经历  
#### 深圳市算法科技有限公司 | 🚀 实习算法工程师 | 2024.8 – 2024.10  
- 📊 **量化交易数据处理：**  
  使用 Tushare Pro 接口高效爬取 A 股市场日线数据（如价格、成交量）及基本面数据（市盈率、每股收益等）。  
- 🧩 **特征工程开发：**  
  - 计算技术指标（MA、RSI、MACD），提取时间特征（年份、月份、星期）。  
  - 构建滑动窗口序列数据，提升模型训练数据质量。  
- 🤖 **基于 BERT 的回归模型开发：**  
  - 预测股票分红金额，优化模型结构，调整超参数（学习率、批次大小等）。  
  - 使用 AdamW 优化器与 Early Stopping 技术防止过拟合，测试集上 RMSE 降低 **10%+**。
---
### 🗂️ 项目经验  
#### 🌾 Global Wheat Detection | Kaggle 竞赛  
- 🔍 **数据处理：** 清洗数据集，处理缺失值和异常值，进行图像增强（旋转、翻转、亮度调整）。  
- 🧠 **模型训练：** 选择 YOLO-V5 目标检测模型，优化超参数与学习率，提升检测性能。  
- 📈 **性能评估：** 通过准确率、召回率与精确度分析模型表现，提出性能优化建议。  
---
#### 📚 深度学习模型微调项目 | 基于 DeepSeek R1 的《失控》知识微调 | 2025  
- **项目概述：** 基于 **DeepSeek-R1:7B** 大模型，完成《失控》一书的知识微调，提升模型对复杂概念的理解与文本生成能力。  
- 🗃️ **数据处理：** 提取并清洗全书文本，构建高质量训练数据，适配监督微调格式。  
- ⚙️ **模型微调：**  
  - 应用 **LoRA（Low-Rank Adaptation）**，显著降低 16GB 显存需求。  
  - 使用 **Transformers、PEFT** 进行模型加载与微调，结合 **DeepSpeed** 提高训练效率。  
  - 集成 **FP16 混合精度训练** 与 **梯度累积**，优化训练速度和模型稳定性。  
- 🚀 **性能优化：**  
  - 调整超参数（学习率、batch size、优化器参数），结合 **AdamW** 与 **Early Stopping** 防止过拟合。  
  - 模型微调后，特定领域知识问答准确率提升 **15%+**。  
- 🛠️ **技术栈：** Python、PyTorch、Transformers、PEFT（LoRA）、DeepSpeed、FP16、AdamW
---
### 💡 技能  
#### 💻 编程语言  
- C/C++、Java、Python、HTML/CSS/JavaScript  
#### 🛠️ 工具与框架  
- Git、MySQL、Spring Boot  
#### 🌍 语言能力  
- 英语（CET-6）、法语（DELF B2）  
---
